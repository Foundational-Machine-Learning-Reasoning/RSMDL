{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canonical Correlation Analysis (CCA)\n",
    "\n",
    "Canonical Correlation Analysis (CCA) is a method used to compare two sets of random variables. The objective of this method is to find two sets of weights that maximize the correlation between the random variables \\(X\\) and \\(Y\\). By training a linear regression, we aim to find \\(w_{R} \\in \\mathbb{R}^{D}\\) and \\(w_{R'} \\in \\mathbb{R}^{D}\\) that satisfy the following equation:\n",
    "\n",
    "$$\\rho := \\rho(R, R') := \\max_{w_R, w_{R'}} \\frac{\\langle R w_R, R' w_{R'} \\rangle}{\\lVert R w_R \\rVert \\cdot \\lVert R' w_{R'} \\rVert}$$\n",
    "\n",
    "The value of \\(\\rho\\) indicates the correlation between the linear combinations of the variables in \\(R\\) and \\(R'\\). A \\(\\rho\\) value close to 1 implies that the representations \\(R\\) and \\(R'\\) are highly similar.\n",
    "\n",
    "We can define two metrics to measure the similarity between the random variables:\n",
    "\n",
    "1. **Standard Representation:**\n",
    "   \n",
    "   $$m_{CCA}(R, R') = \\frac{1}{D} \\sum_{i=1}^D \\rho_i$$\n",
    "\n",
    "2. **Yanai's Generalized Coefficient of Determination:**\n",
    "\n",
    "   $$m_{CCA}^2(R, R') = \\frac{1}{D} \\sum_{i=1}^D \\rho_i^2$$\n",
    "\n",
    "These metrics provide a quantitative measure of the similarity between the sets of variables based on their canonical correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation in torch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def mean_center(X):\n",
    "    \"\"\"Mean center the data, due to this method Assume mean-centered representations\"\"\"\n",
    "    return X - X.mean(dim=0)\n",
    "\n",
    "def compute_covariance_matrices(X, Y):\n",
    "    n_samples = X.size(0)\n",
    "    sigma_X = X.T @ X / (n_samples - 1)\n",
    "    sigma_Y = Y.T @ Y / (n_samples - 1)\n",
    "    sigma_XY = X.T @ Y / (n_samples - 1)\n",
    "    return sigma_X, sigma_Y, sigma_XY\n",
    "\n",
    "def compute_inverse_sqrt_matrix(matrix):\n",
    "    eigvals, eigvecs = torch.linalg.eigh(matrix)\n",
    "    eigvals = torch.clamp(eigvals, min=1e-10)  # Avoid division by zero\n",
    "    inv_sqrt_matrix = eigvecs @ torch.diag(1.0 / torch.sqrt(eigvals)) @ eigvecs.T\n",
    "    return inv_sqrt_matrix\n",
    "\n",
    "def compute_cca(X, Y, output_dim):\n",
    "    # Center the data\n",
    "    X_centered = mean_center(X)\n",
    "    Y_centered = mean_center(Y)\n",
    "    \n",
    "    # Compute covariance matrices\n",
    "    sigma_X, sigma_Y, sigma_XY = compute_covariance_matrices(X_centered, Y_centered)\n",
    "    \n",
    "    # Compute inverse square roots of covariance matrices\n",
    "    sqrt_inv_sigma_X = compute_inverse_sqrt_matrix(sigma_X)\n",
    "    sqrt_inv_sigma_Y = compute_inverse_sqrt_matrix(sigma_Y)\n",
    "    \n",
    "    # Compute the transformation matrix\n",
    "    T = sqrt_inv_sigma_X @ sigma_XY @ sqrt_inv_sigma_Y\n",
    "    \n",
    "    # Perform SVD on the transformation matrix\n",
    "    U, S, V = torch.svd(T)\n",
    "    \n",
    "    # Select the top output_dim components\n",
    "    X_c = X_centered @ sqrt_inv_sigma_X @ U\n",
    "    Y_c = Y_centered @ sqrt_inv_sigma_Y @ V\n",
    "    \n",
    "    return X_c, Y_c, S\n",
    "\n",
    "def compute_standard_cca(X, Y):\n",
    "    _, _, S = compute_cca(X, Y, min(X.size(1), Y.size(1)))\n",
    "    return float(1/X.size(1) * torch.sum(S))\n",
    "\n",
    "def compute_yanai_cca(X, Y):\n",
    "    _, _, S = compute_cca(X, Y, min(X.size(1), Y.size(1)))\n",
    "    return float(1/X.size(1) * torch.sum(S**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canonical Correlations (rho): tensor([0.5262, 0.4921, 0.3742, 0.3318, 0.3189, 0.2431, 0.2374, 0.1553, 0.0787,\n",
      "        0.0172])\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "X = torch.rand(100, 10)  # 100 samples, 10 features\n",
    "Y = torch.rand(100, 10)  # 100 samples, 10 features\n",
    "\n",
    "# Set the number of components you want to keep\n",
    "output_dim = 1\n",
    "\n",
    "# Perform CCA\n",
    "X_c, Y_c, canonical_correlations = compute_cca(X, Y, output_dim)\n",
    "\n",
    "# The canonical correlations (rho) are the singular values S from the SVD\n",
    "rho = canonical_correlations\n",
    "print(\"Canonical Correlations (rho):\", rho)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2774849832057953\n",
      "0.10169340670108795\n"
     ]
    }
   ],
   "source": [
    "print(compute_standard_cca(X, Y))\n",
    "print(compute_yanai_cca(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value CCA\n",
    "\n",
    "Intuitively, an eigenvector is a vector whose direction remains unchanged when a linear transformation is applied to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(X, variance_retained=0.99):\n",
    "    \"\"\"Perform PCA on the data to retain the specified amount of variance.\"\"\"\n",
    "    X_centered = X - X.mean(dim=0)\n",
    "    \n",
    "    # Compute covariance matrix\n",
    "    covariance_matrix = (X_centered.T @ X_centered) / (X_centered.size(0) - 1)\n",
    "    \n",
    "    # Compute eigenvalues and eigenvectors\n",
    "    eigvals, eigvecs = torch.linalg.eigh(covariance_matrix)\n",
    "    \n",
    "    # Sort eigenvalues and eigenvectors in descending order\n",
    "    sorted_indices = torch.argsort(eigvals, descending=True)\n",
    "    eigvals = eigvals[sorted_indices]\n",
    "    eigvecs = eigvecs[:, sorted_indices]\n",
    "    \n",
    "    # Compute the cumulative explained variance\n",
    "    explained_variance = eigvals / eigvals.sum()\n",
    "    cumulative_variance = torch.cumsum(explained_variance, dim=0)\n",
    "    \n",
    "    # Determine the number of components to retain\n",
    "    num_components = torch.searchsorted(cumulative_variance, variance_retained).item() + 1\n",
    "    \n",
    "    # Project the data onto the principal components\n",
    "    principal_components = eigvecs[:, :num_components]\n",
    "    X_pca = X_centered @ principal_components\n",
    "    \n",
    "    return X_pca, principal_components\n",
    "\n",
    "def compute_standard_svcca(X, Y, variance_retained=0.99):\n",
    "    X_pca, _ = pca(X, variance_retained)\n",
    "    Y_pca, _ = pca(Y, variance_retained)\n",
    "    \n",
    "    _, _, S = compute_cca(X_pca, Y_pca, min(X.size(1), Y.size(1)))\n",
    "    return float(1/X.size(1) * torch.sum(S))\n",
    "\n",
    "def compute_yanai_svcca(X, Y, variance_retained=0.99):\n",
    "    X_pca, _ = pca(X, variance_retained)\n",
    "    Y_pca, _ = pca(Y, variance_retained)\n",
    "\n",
    "    _, _, S = compute_cca(X_pca, Y_pca, min(X.size(1), Y.size(1)))\n",
    "    return float(1/X.size(1) * torch.sum(S**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27748483419418335"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_standard_svcca(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection Weighted CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_wvcca(X, Y, output_dim=1):\n",
    "\n",
    "    X_c, _, S = compute_cca(X, Y, output_dim)\n",
    "    \n",
    "    output_dim = X_c.size(1)\n",
    "    X = mean_center(X)\n",
    "    weights = torch.zeros(output_dim)\n",
    "    for i in range(output_dim):\n",
    "        Xw = X.T @ X_c[:, i]\n",
    "        weights[i] = torch.abs(torch.sum(Xw @ X.T))\n",
    "\n",
    "    # Normalize the weights\n",
    "    weights = weights / torch.sum(weights)\n",
    "    # Compute the final PWCCA measure\n",
    "    return float(torch.sum(weights * S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999998211860657"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_wvcca(X, X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backbones",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
